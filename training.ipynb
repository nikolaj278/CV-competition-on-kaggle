{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":25563,"databundleVersionId":2094376,"sourceType":"competition"}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torchvision import transforms","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T10:24:03.634046Z","iopub.execute_input":"2025-10-17T10:24:03.634238Z","iopub.status.idle":"2025-10-17T10:24:13.469312Z","shell.execute_reply.started":"2025-10-17T10:24:03.634221Z","shell.execute_reply":"2025-10-17T10:24:13.468759Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T10:24:13.470631Z","iopub.execute_input":"2025-10-17T10:24:13.471022Z","iopub.status.idle":"2025-10-17T10:24:13.537446Z","shell.execute_reply.started":"2025-10-17T10:24:13.471002Z","shell.execute_reply":"2025-10-17T10:24:13.536637Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"class TrainDataset(Dataset):\n    def __init__(self, path, image_folder, label_file, transform):\n        df = pd.read_csv(path + label_file)\n        classes = df.labels.astype(str)\n        \n        self.image_paths = [path + image_folder + f for f in df.image]\n        self.cls2idx = {c:i for i, c in enumerate(sorted(classes.unique()))}\n        self.idx2cls = list(sorted(classes.unique()))\n        self.y = classes.map(self.cls2idx).to_numpy()\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, i):\n        img = Image.open(self.image_paths[i]).convert(\"RGB\")\n        img = self.transform(img)\n        label = torch.tensor(self.y[i], dtype=torch.long)\n        return img, label\n\nclass TestDataset(Dataset):\n    def __init__(self, path, folder, transform):\n        self.path = path + folder \n        self.image_names = [f for f in os.listdir(self.path)]\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_names)\n\n    def __getitem__(self, i):\n        img = Image.open(self.path + self.image_names[i]).convert(\"RGB\")\n        img = self.transform(img)\n\n        return img, self.image_names[i]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T10:24:13.538445Z","iopub.execute_input":"2025-10-17T10:24:13.539373Z","iopub.status.idle":"2025-10-17T10:24:13.559045Z","shell.execute_reply.started":"2025-10-17T10:24:13.539341Z","shell.execute_reply":"2025-10-17T10:24:13.558420Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedShuffleSplit\nfrom torch.utils.data import Subset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T10:24:13.559803Z","iopub.execute_input":"2025-10-17T10:24:13.560071Z","iopub.status.idle":"2025-10-17T10:24:14.677970Z","shell.execute_reply.started":"2025-10-17T10:24:13.560053Z","shell.execute_reply":"2025-10-17T10:24:14.677202Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"\nimport kornia as K\nfrom kornia.augmentation import AugmentationSequential, RandomRotation, RandomVerticalFlip\n\naug = AugmentationSequential(\n    RandomRotation(degrees=90),\n    RandomVerticalFlip(p=0.5),\n    data_keys=[\"input\"],         \n    same_on_batch=False,\n).to(device)\n\ntrain_tfms = transforms.Compose([transforms.Resize((224, 224)),\n                                 transforms.ToTensor(),\n                                 transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                 std=[0.229, 0.224, 0.225])\n                                ])\n\n\ntest_tfms = transforms.Compose([transforms.Resize((224, 224)),\n                                transforms.ToTensor(),\n                                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                 std=[0.229, 0.224, 0.225])\n                               ])\n\nPATH = '/kaggle/input/plant-pathology-2021-fgvc8/'\n\ntrain_dataset = TrainDataset(PATH, 'train_images/', 'train.csv', train_tfms)\nval_dataset = TrainDataset(PATH, 'train_images/', 'train.csv', train_tfms)\ntest_dataset = TestDataset(PATH, 'test_images/', test_tfms)\n\n\ny = train_dataset.y  \nsss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\ntrain_idx, val_idx = next(sss.split(np.zeros(len(y)), y))\n\ntrain_subset = Subset(train_dataset, train_idx)  \nval_subset = Subset(val_dataset,   val_idx)   \n\nbatch_size = 128\nnum_workers = 4   # start low; increase only if GPU starves\nprefetch_factor = 4\n\ntrain_loader = DataLoader(\n    train_subset, batch_size=batch_size, shuffle=True,\n    num_workers=num_workers, pin_memory=True, persistent_workers=True, \n    prefetch_factor=prefetch_factor\n)\nval_loader = DataLoader(\n    val_subset, batch_size=batch_size,\n    num_workers=num_workers, pin_memory=True, persistent_workers=True, \n    prefetch_factor=prefetch_factor\n)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size,\n    num_workers=num_workers, pin_memory=True, persistent_workers=True, \n                         prefetch_factor=prefetch_factor)\n\nfull_train_loader = DataLoader(\n    train_dataset, batch_size=batch_size, shuffle=True,\n    num_workers=num_workers, pin_memory=True, persistent_workers=True, \n    prefetch_factor=prefetch_factor \n)\n\ntorch.backends.cudnn.benchmark = True  # once, after imports","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T10:26:06.470106Z","iopub.execute_input":"2025-10-17T10:26:06.470652Z","iopub.status.idle":"2025-10-17T10:26:06.538973Z","shell.execute_reply.started":"2025-10-17T10:26:06.470621Z","shell.execute_reply":"2025-10-17T10:26:06.538361Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"from collections import OrderedDict  \nfrom torch import nn, optim\nfrom torchvision.models import resnet50","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T10:26:06.988437Z","iopub.execute_input":"2025-10-17T10:26:06.988952Z","iopub.status.idle":"2025-10-17T10:26:06.994356Z","shell.execute_reply.started":"2025-10-17T10:26:06.988919Z","shell.execute_reply":"2025-10-17T10:26:06.993163Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"model = resnet50(weights='DEFAULT')\n\nmodel.fc = nn.Sequential(OrderedDict([\n    ('fc1', nn.Linear(2048, 128)),\n    ('relu1', nn.ReLU()),\n    ('droupout1', nn.Dropout(0.4)),\n    ('fc2', nn.Linear(128, 12))\n]))\n\nmodel = model.to(device)\n# model = nn.DataParallel(model, device_ids=[0,1])\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.fc.parameters(), lr=1e-3) #model.module.fc.parameters() if use both gpus\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min')\n\n# scaler = torch.amp.GradScaler('cuda')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T10:26:07.636229Z","iopub.execute_input":"2025-10-17T10:26:07.636921Z","iopub.status.idle":"2025-10-17T10:26:08.164219Z","shell.execute_reply.started":"2025-10-17T10:26:07.636895Z","shell.execute_reply":"2025-10-17T10:26:08.163381Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"from tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T10:26:09.875136Z","iopub.execute_input":"2025-10-17T10:26:09.875843Z","iopub.status.idle":"2025-10-17T10:26:09.879155Z","shell.execute_reply.started":"2025-10-17T10:26:09.875816Z","shell.execute_reply":"2025-10-17T10:26:09.878375Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"for epoch in range(5):\n    train_loss_acum = 0\n    correct_count_train = 0\n    for ii, (images, labels) in tqdm(enumerate(train_loader), total=len(train_loader)):\n        images_gpu = images.to(device, non_blocking=True)\n        labels_gpu = labels.to(device, non_blocking=True)\n\n        images_gpu = aug(images_gpu) #augmentations with kornia\n        \n        optimizer.zero_grad()\n        logits = model(images_gpu)\n        loss = criterion(logits, labels_gpu)\n        loss.backward()\n        optimizer.step()\n        # with torch.amp.autocast('cuda'):  \n        #     logits = model(images_gpu)\n        #     loss = criterion(logits, labels_gpu)\n        # scaler.scale(loss).backward()\n        # scaler.step(optimizer)\n        # scaler.update()\n        correct_count_train += (torch.argmax(logits, dim=-1) == labels_gpu).sum()\n        train_loss_acum += loss * labels.shape[0] #acum loss by every elem\n        \n    train_loss = train_loss_acum / len(train_dataset)\n    train_acc = correct_count_train/len(train_subset)\n    print(f'epoch {epoch}, train acc = {train_acc}')\n        \n    with torch.no_grad():\n        model.eval()\n        val_loss_acum = 0\n        correct_pred_count = 0\n        for iii, (val_images, val_labels) in tqdm(enumerate(val_loader), total=len(val_loader)):\n            val_images_gpu = val_images.to(device, non_blocking=True)\n            val_labels_gpu = val_labels.to(device, non_blocking=True)\n            # with torch.amp.autocast('cuda'):\n            #     val_logits = model(val_images_gpu)\n            #     val_loss += criterion(val_logits, val_labels_gpu)\n            val_logits = model(val_images_gpu)\n            correct_pred_count += (torch.argmax(val_logits, dim=-1) == val_labels_gpu).sum()\n            val_loss_acum += criterion(val_logits, val_labels_gpu) * val_labels_gpu.shape[0]\n            \n        val_acc = correct_pred_count / len(val_subset) \n        val_loss = val_loss_acum / len(val_dataset)\n        \n    model.train()\n    scheduler.step(val_loss)\n    print(f'epoch {epoch} train loss = {train_loss}, val loss = {val_loss}, val acc = {val_acc}')\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T10:38:24.881415Z","iopub.execute_input":"2025-10-17T10:38:24.882148Z","iopub.status.idle":"2025-10-17T11:45:56.293262Z","shell.execute_reply.started":"2025-10-17T10:38:24.882124Z","shell.execute_reply":"2025-10-17T11:45:56.292092Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 117/117 [10:21<00:00,  5.31s/it]\n","output_type":"stream"},{"name":"stdout","text":"epoch 0, train acc = 0.6884267330169678\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 30/30 [03:08<00:00,  6.30s/it]\n","output_type":"stream"},{"name":"stdout","text":"epoch 0 train loss = 117.97583770751953, val loss = 27.035797119140625, val acc = 0.727662980556488\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 117/117 [09:58<00:00,  5.11s/it]\n","output_type":"stream"},{"name":"stdout","text":"epoch 1, train acc = 0.7162697315216064\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 30/30 [02:58<00:00,  5.96s/it]\n","output_type":"stream"},{"name":"stdout","text":"epoch 1 train loss = 106.35456848144531, val loss = 25.089500427246094, val acc = 0.7367856502532959\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 117/117 [10:53<00:00,  5.58s/it]\n","output_type":"stream"},{"name":"stdout","text":"epoch 2, train acc = 0.7299564480781555\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 30/30 [03:13<00:00,  6.45s/it]\n","output_type":"stream"},{"name":"stdout","text":"epoch 2 train loss = 100.8189468383789, val loss = 24.465770721435547, val acc = 0.7445666790008545\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 117/117 [10:14<00:00,  5.25s/it]\n","output_type":"stream"},{"name":"stdout","text":"epoch 3, train acc = 0.7468634843826294\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 30/30 [03:12<00:00,  6.42s/it]\n","output_type":"stream"},{"name":"stdout","text":"epoch 3 train loss = 95.25563049316406, val loss = 23.675460815429688, val acc = 0.7507378458976746\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 117/117 [10:11<00:00,  5.23s/it]\n","output_type":"stream"},{"name":"stdout","text":"epoch 4, train acc = 0.7510902881622314\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 30/30 [03:16<00:00,  6.54s/it]","output_type":"stream"},{"name":"stdout","text":"epoch 4 train loss = 92.51350402832031, val loss = 22.94195556640625, val acc = 0.7590555548667908\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"### It will be a good thing to infere the accuracy by each class. I will probabrly find out then which class is misclassified most.","metadata":{}},{"cell_type":"code","source":"ckpt = {\"state_dict\": model.state_dict()}\ntorch.save(ckpt, \"/kaggle/working/model_resnet50_fold0.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T11:45:56.295392Z","iopub.execute_input":"2025-10-17T11:45:56.295710Z","iopub.status.idle":"2025-10-17T11:45:56.447460Z","shell.execute_reply.started":"2025-10-17T11:45:56.295681Z","shell.execute_reply":"2025-10-17T11:45:56.446873Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# import pandas\n\n# model.eval()\n# all_files, all_idx = [], []\n# for test_image, file_names in test_loader:\n#     test_image = test_image.to(device)\n#     preds = torch.argmax(model(test_image), dim=-1).cpu().tolist()\n#     all_idx.extend(preds)\n#     all_files.extend(file_names)\n\n# df = pd.DataFrame({'image': all_files, 'lables': [train_dataset.idx2cls[i] for i in all_idx]})\n# df.to_csv('submission.csv', index=False)\n# df.head(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T10:25:42.953363Z","iopub.status.idle":"2025-10-17T10:25:42.953952Z","shell.execute_reply.started":"2025-10-17T10:25:42.953772Z","shell.execute_reply":"2025-10-17T10:25:42.953789Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# print(device, next(model.parameters()).device)\n# !nvidia-smi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T10:25:42.955002Z","iopub.status.idle":"2025-10-17T10:25:42.955283Z","shell.execute_reply.started":"2025-10-17T10:25:42.955165Z","shell.execute_reply":"2025-10-17T10:25:42.955177Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}