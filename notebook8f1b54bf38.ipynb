{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":25563,"databundleVersionId":2094376,"sourceType":"competition"}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torchvision import transforms","metadata":{"trusted":true,"execution":{"iopub.status.idle":"2025-10-15T12:47:14.363042Z","shell.execute_reply.started":"2025-10-15T12:47:11.249459Z","shell.execute_reply":"2025-10-15T12:47:14.362181Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T12:47:14.366765Z","iopub.execute_input":"2025-10-15T12:47:14.367043Z","iopub.status.idle":"2025-10-15T12:47:14.424398Z","shell.execute_reply.started":"2025-10-15T12:47:14.367015Z","shell.execute_reply":"2025-10-15T12:47:14.423621Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"class TrainDataset(Dataset):\n    def __init__(self, path, image_folder, label_file, transform):\n        df = pd.read_csv(path + label_file)\n        classes = df.labels.astype(str)\n        \n        self.image_paths = [path + image_folder + f for f in df.image]\n        self.cls2idx = {c:i for i, c in enumerate(sorted(classes.unique()))}\n        self.idx2cls = list(sorted(classes.unique()))\n        self.y = classes.map(self.cls2idx).to_numpy()\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, i):\n        img = Image.open(self.image_paths[i]).convert(\"RGB\")\n        img = self.transform(img)\n        label = torch.tensor(self.y[i], dtype=torch.long)\n        return img, label\n\nclass TestDataset(Dataset):\n    def __init__(self, path, folder, transform):\n        self.path = path + folder \n        self.image_names = [f for f in os.listdir(self.path)]\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_names)\n\n    def __getitem__(self, i):\n        img = Image.open(self.path + self.image_names[i]).convert(\"RGB\")\n        img = self.transform(img)\n\n        return img, self.image_names[i]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T13:37:02.830485Z","iopub.execute_input":"2025-10-15T13:37:02.831129Z","iopub.status.idle":"2025-10-15T13:37:02.838610Z","shell.execute_reply.started":"2025-10-15T13:37:02.831104Z","shell.execute_reply":"2025-10-15T13:37:02.837809Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedShuffleSplit\nfrom torch.utils.data import Subset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T13:37:06.605482Z","iopub.execute_input":"2025-10-15T13:37:06.605994Z","iopub.status.idle":"2025-10-15T13:37:06.609648Z","shell.execute_reply.started":"2025-10-15T13:37:06.605962Z","shell.execute_reply":"2025-10-15T13:37:06.608869Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"\nimport kornia as K\nfrom kornia.augmentation import AugmentationSequential, RandomRotation, RandomVerticalFlip\n\naug = AugmentationSequential(\n    RandomRotation(degrees=90),\n    RandomVerticalFlip(p=0.3),\n    data_keys=[\"input\"],         \n    same_on_batch=False,\n).to(device)\n\ntrain_tfms = transforms.Compose([transforms.Resize((224, 224)),\n                                 transforms.ToTensor(),\n                                 transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                 std=[0.229, 0.224, 0.225])\n                                ])\n\n\ntest_tfms = transforms.Compose([transforms.Resize((224, 224)),\n                                transforms.ToTensor(),\n                                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                 std=[0.229, 0.224, 0.225])\n                               ])\n\nPATH = '/kaggle/input/plant-pathology-2021-fgvc8/'\n\ntrain_dataset = TrainDataset(PATH, 'train_images/', 'train.csv', train_tfms)\nval_dataset = TrainDataset(PATH, 'train_images/', 'train.csv', train_tfms)\ntest_dataset = TestDataset(PATH, 'test_images/', test_tfms)\n\n\ny = train_dataset.y  \nsss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\ntrain_idx, val_idx = next(sss.split(np.zeros(len(y)), y))\n\ntrain_data = Subset(train_dataset, train_idx)  \nval_data = Subset(val_dataset,   val_idx)   \n\nbatch_size = 256\nnum_workers = 4   # start low; increase only if GPU starves\nprefetch_factor = 4\n\ntrain_loader = DataLoader(\n    train_data, batch_size=batch_size, shuffle=True,\n    num_workers=num_workers, pin_memory=True, persistent_workers=True, \n    prefetch_factor=prefetch_factor\n)\nval_loader = DataLoader(\n    val_data, batch_size=batch_size,\n    num_workers=num_workers, pin_memory=True, persistent_workers=True, \n    prefetch_factor=prefetch_factor\n)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size,\n    num_workers=num_workers, pin_memory=True, persistent_workers=True, \n                         prefetch_factor=prefetch_factor)\n\n\n\ntorch.backends.cudnn.benchmark = True  # once, after imports","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T13:37:07.053544Z","iopub.execute_input":"2025-10-15T13:37:07.054076Z","iopub.status.idle":"2025-10-15T13:37:07.227501Z","shell.execute_reply.started":"2025-10-15T13:37:07.054032Z","shell.execute_reply":"2025-10-15T13:37:07.226774Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"from collections import OrderedDict  \nfrom torch import nn, optim\nfrom torchvision.models import resnet18","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T13:37:12.185516Z","iopub.execute_input":"2025-10-15T13:37:12.185784Z","iopub.status.idle":"2025-10-15T13:37:12.190206Z","shell.execute_reply.started":"2025-10-15T13:37:12.185765Z","shell.execute_reply":"2025-10-15T13:37:12.189190Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"model = resnet18(pretrained=True)\n\nmodel.fc = nn.Sequential(OrderedDict([\n    ('fc1', nn.Linear(512, 128)),\n    ('relu1', nn.ReLU()),\n    ('droupout1', nn.Dropout(0.2)),\n    ('fc2', nn.Linear(128, 12))\n]))\n\nmodel = model.to(device)\n# model = nn.DataParallel(model, device_ids=[0,1])\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.fc.parameters(), lr=1e-3) #model.module.fc.parameters() if use both gpus\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min')\n\nscaler = torch.amp.GradScaler('cuda')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T13:37:12.762299Z","iopub.execute_input":"2025-10-15T13:37:12.763053Z","iopub.status.idle":"2025-10-15T13:37:13.029873Z","shell.execute_reply.started":"2025-10-15T13:37:12.763022Z","shell.execute_reply":"2025-10-15T13:37:13.029240Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nTraceback (most recent call last):\n  File \"/usr/lib/python3.11/multiprocessing/queues.py\", line 239, in _feed\n    reader_close()\n  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 178, in close\n    self._close()\n  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 377, in _close\n    _close(self._handle)\nOSError: [Errno 9] Bad file descriptor\n","output_type":"stream"}],"execution_count":57},{"cell_type":"code","source":"from tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T12:56:09.139430Z","iopub.execute_input":"2025-10-15T12:56:09.139998Z","iopub.status.idle":"2025-10-15T12:56:09.143554Z","shell.execute_reply.started":"2025-10-15T12:56:09.139977Z","shell.execute_reply":"2025-10-15T12:56:09.142829Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"for epoch in range(1):\n    epoch_loss = 0\n    correct_count_train = 0\n    for ii, (images, labels) in tqdm(enumerate(train_loader), total=len(train_loader)):\n        images_gpu = images.to(device, non_blocking=True)\n        labels_gpu = labels.to(device, non_blocking=True)\n\n        images_gpu = aug(images_gpu) #augmentations with kornia\n        \n        optimizer.zero_grad()\n        with torch.amp.autocast('cuda'):  \n            logits = model(images_gpu)\n            loss = criterion(logits, labels_gpu)\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        correct_count_train += (torch.argmax(logits, dim=-1) == labels_gpu).sum()\n        epoch_loss += loss\n    train_acc = correct_count_train/len(train_data)\n    print(f'epoch {epoch}, train acc = {train_acc}')\n        \n    with torch.no_grad():\n        model.eval()\n        val_loss = 0\n        correct_pred_count = 0\n        for iii, (val_images, val_labels) in tqdm(enumerate(val_loader), total=len(val_loader)):\n            val_images_gpu = val_images.to(device, non_blocking=True)\n            val_labels_gpu = val_labels.to(device, non_blocking=True)\n            with torch.amp.autocast('cuda'):\n                val_logits = model(val_images_gpu)\n                val_loss += criterion(val_logits, val_labels_gpu)\n            correct_pred_count += (torch.argmax(val_logits, dim=-1) == val_labels_gpu).sum()\n        val_acc = correct_pred_count / len(val_data) \n    model.train()\n    scheduler.step(val_loss)\n    print(f'epoch {epoch} train loss = {epoch_loss}, val loss = {val_loss}, val acc = {val_acc}')\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T13:15:57.596551Z","iopub.execute_input":"2025-10-15T13:15:57.596828Z","iopub.status.idle":"2025-10-15T13:16:00.741995Z","shell.execute_reply.started":"2025-10-15T13:15:57.596808Z","shell.execute_reply":"2025-10-15T13:16:00.735956Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stderr","text":"  0%|          | 0/59 [00:02<?, ?it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_1203/1478660626.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcorrect_count_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mimages_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mlabels_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1457\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1459\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1408\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1410\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1411\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1412\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1249\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":44},{"cell_type":"code","source":"import pandas\n\nmodel.eval()\nall_files, all_idx = [], []\nfor test_image, file_names in test_loader:\n    test_image = test_image.to(device)\n    preds = torch.argmax(model(test_image), dim=-1).cpu().tolist()\n    all_idx.extend(preds)\n    all_files.extend(file_names)\n\ndf = pd.DataFrame({'image': all_files, 'lables': [train_dataset.idx2cls[i] for i in all_idx]})\ndf.to_csv('submission.csv', index=False)\ndf.head(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T13:38:30.448645Z","iopub.execute_input":"2025-10-15T13:38:30.449469Z","iopub.status.idle":"2025-10-15T13:38:31.256744Z","shell.execute_reply.started":"2025-10-15T13:38:30.449441Z","shell.execute_reply":"2025-10-15T13:38:31.255488Z"}},"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"                  image          lables\n0  ad8770db05586b59.jpg            scab\n1  c7b03e718489f3ca.jpg  powdery_mildew\n2  85f8cb619c66b863.jpg  powdery_mildew","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>lables</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ad8770db05586b59.jpg</td>\n      <td>scab</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>c7b03e718489f3ca.jpg</td>\n      <td>powdery_mildew</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>85f8cb619c66b863.jpg</td>\n      <td>powdery_mildew</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":59},{"cell_type":"code","source":"print(device, next(model.parameters()).device)\n!nvidia-smi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T12:55:10.806958Z","iopub.execute_input":"2025-10-15T12:55:10.807625Z","iopub.status.idle":"2025-10-15T12:55:11.093565Z","shell.execute_reply.started":"2025-10-15T12:55:10.807601Z","shell.execute_reply":"2025-10-15T12:55:11.092543Z"}},"outputs":[{"name":"stdout","text":"cuda:0 cuda:0\nWed Oct 15 12:55:10 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   72C    P0             31W /   70W |    4855MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   74C    P0             34W /   70W |     253MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}