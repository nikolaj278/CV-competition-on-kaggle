{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":25563,"databundleVersionId":2094376,"sourceType":"competition"}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torchvision import transforms","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T04:55:57.988457Z","iopub.execute_input":"2025-10-17T04:55:57.988725Z","iopub.status.idle":"2025-10-17T04:56:09.341703Z","shell.execute_reply.started":"2025-10-17T04:55:57.988703Z","shell.execute_reply":"2025-10-17T04:56:09.340921Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T04:56:09.343095Z","iopub.execute_input":"2025-10-17T04:56:09.343395Z","iopub.status.idle":"2025-10-17T04:56:09.428855Z","shell.execute_reply.started":"2025-10-17T04:56:09.343377Z","shell.execute_reply":"2025-10-17T04:56:09.427772Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"class TrainDataset(Dataset):\n    def __init__(self, path, image_folder, label_file, transform):\n        df = pd.read_csv(path + label_file)\n        classes = df.labels.astype(str)\n        \n        self.image_paths = [path + image_folder + f for f in df.image]\n        self.cls2idx = {c:i for i, c in enumerate(sorted(classes.unique()))}\n        self.idx2cls = list(sorted(classes.unique()))\n        self.y = classes.map(self.cls2idx).to_numpy()\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, i):\n        img = Image.open(self.image_paths[i]).convert(\"RGB\")\n        img = self.transform(img)\n        label = torch.tensor(self.y[i], dtype=torch.long)\n        return img, label\n\nclass TestDataset(Dataset):\n    def __init__(self, path, folder, transform):\n        self.path = path + folder \n        self.image_names = [f for f in os.listdir(self.path)]\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_names)\n\n    def __getitem__(self, i):\n        img = Image.open(self.path + self.image_names[i]).convert(\"RGB\")\n        img = self.transform(img)\n\n        return img, self.image_names[i]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T04:56:09.430021Z","iopub.execute_input":"2025-10-17T04:56:09.430270Z","iopub.status.idle":"2025-10-17T04:56:09.446372Z","shell.execute_reply.started":"2025-10-17T04:56:09.430248Z","shell.execute_reply":"2025-10-17T04:56:09.445634Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedShuffleSplit\nfrom torch.utils.data import Subset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T04:56:09.448182Z","iopub.execute_input":"2025-10-17T04:56:09.448699Z","iopub.status.idle":"2025-10-17T04:56:10.783541Z","shell.execute_reply.started":"2025-10-17T04:56:09.448672Z","shell.execute_reply":"2025-10-17T04:56:10.782911Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"\nimport kornia as K\nfrom kornia.augmentation import AugmentationSequential, RandomRotation, RandomVerticalFlip\n\naug = AugmentationSequential(\n    RandomRotation(degrees=90),\n    RandomVerticalFlip(p=0.3),\n    data_keys=[\"input\"],         \n    same_on_batch=False,\n).to(device)\n\ntrain_tfms = transforms.Compose([transforms.Resize((224, 224)),\n                                 transforms.ToTensor(),\n                                 transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                 std=[0.229, 0.224, 0.225])\n                                ])\n\n\ntest_tfms = transforms.Compose([transforms.Resize((224, 224)),\n                                transforms.ToTensor(),\n                                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                 std=[0.229, 0.224, 0.225])\n                               ])\n\nPATH = '/kaggle/input/plant-pathology-2021-fgvc8/'\n\ntrain_dataset = TrainDataset(PATH, 'train_images/', 'train.csv', train_tfms)\nval_dataset = TrainDataset(PATH, 'train_images/', 'train.csv', train_tfms)\ntest_dataset = TestDataset(PATH, 'test_images/', test_tfms)\n\n\ny = train_dataset.y  \nsss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\ntrain_idx, val_idx = next(sss.split(np.zeros(len(y)), y))\n\ntrain_subset = Subset(train_dataset, train_idx)  \nval_subset = Subset(val_dataset,   val_idx)   \n\nbatch_size = 128\nnum_workers = 4   # start low; increase only if GPU starves\nprefetch_factor = 4\n\ntrain_loader = DataLoader(\n    train_subset, batch_size=batch_size, shuffle=True,\n    num_workers=num_workers, pin_memory=True, persistent_workers=True, \n    prefetch_factor=prefetch_factor\n)\nval_loader = DataLoader(\n    val_subset, batch_size=batch_size,\n    num_workers=num_workers, pin_memory=True, persistent_workers=True, \n    prefetch_factor=prefetch_factor\n)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size,\n    num_workers=num_workers, pin_memory=True, persistent_workers=True, \n                         prefetch_factor=prefetch_factor)\n\nfull_train_loader = DataLoader(\n    train_dataset, batch_size=batch_size, shuffle=True,\n    num_workers=num_workers, pin_memory=True, persistent_workers=True, \n    prefetch_factor=prefetch_factor \n)\n\ntorch.backends.cudnn.benchmark = True  # once, after imports","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T04:57:11.883127Z","iopub.execute_input":"2025-10-17T04:57:11.883397Z","iopub.status.idle":"2025-10-17T04:57:11.946444Z","shell.execute_reply.started":"2025-10-17T04:57:11.883377Z","shell.execute_reply":"2025-10-17T04:57:11.945915Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"from collections import OrderedDict  \nfrom torch import nn, optim\nfrom torchvision.models import resnet18","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T04:57:12.369064Z","iopub.execute_input":"2025-10-17T04:57:12.369345Z","iopub.status.idle":"2025-10-17T04:57:12.373199Z","shell.execute_reply.started":"2025-10-17T04:57:12.369325Z","shell.execute_reply":"2025-10-17T04:57:12.372435Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"model = resnet18(weights='DEFAULT')\n\nmodel.fc = nn.Sequential(OrderedDict([\n    ('fc1', nn.Linear(512, 128)),\n    ('relu1', nn.ReLU()),\n    ('droupout1', nn.Dropout(0.2)),\n    ('fc2', nn.Linear(128, 12))\n]))\n\nmodel = model.to(device)\n# model = nn.DataParallel(model, device_ids=[0,1])\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.fc.parameters(), lr=1e-3) #model.module.fc.parameters() if use both gpus\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min')\n\nscaler = torch.amp.GradScaler('cuda')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T04:57:12.892680Z","iopub.execute_input":"2025-10-17T04:57:12.892959Z","iopub.status.idle":"2025-10-17T04:57:13.141314Z","shell.execute_reply.started":"2025-10-17T04:57:12.892939Z","shell.execute_reply":"2025-10-17T04:57:13.140697Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"from tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T04:57:15.332868Z","iopub.execute_input":"2025-10-17T04:57:15.333188Z","iopub.status.idle":"2025-10-17T04:57:15.336843Z","shell.execute_reply.started":"2025-10-17T04:57:15.333167Z","shell.execute_reply":"2025-10-17T04:57:15.336221Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"for epoch in range(3):\n    epoch_loss = 0\n    correct_count_train = 0\n    for ii, (images, labels) in tqdm(enumerate(train_loader), total=len(train_loader)):\n        images_gpu = images.to(device, non_blocking=True)\n        labels_gpu = labels.to(device, non_blocking=True)\n\n        images_gpu = aug(images_gpu) #augmentations with kornia\n        \n        optimizer.zero_grad()\n        logits = model(images_gpu)\n        loss = criterion(logits, labels_gpu)\n        loss.backward()\n        optimizer.step()\n        # with torch.amp.autocast('cuda'):  \n        #     logits = model(images_gpu)\n        #     loss = criterion(logits, labels_gpu)\n        # scaler.scale(loss).backward()\n        # scaler.step(optimizer)\n        # scaler.update()\n        correct_count_train += (torch.argmax(logits, dim=-1) == labels_gpu).sum()\n        epoch_loss += loss\n    train_acc = correct_count_train/len(train_data)\n    print(f'epoch {epoch}, train acc = {train_acc}')\n        \n    with torch.no_grad():\n        model.eval()\n        val_loss = 0\n        correct_pred_count = 0\n        for iii, (val_images, val_labels) in tqdm(enumerate(val_loader), total=len(val_loader)):\n            val_images_gpu = val_images.to(device, non_blocking=True)\n            val_labels_gpu = val_labels.to(device, non_blocking=True)\n            # with torch.amp.autocast('cuda'):\n            #     val_logits = model(val_images_gpu)\n            #     val_loss += criterion(val_logits, val_labels_gpu)\n            val_logits = model(val_images_gpu)\n            val_loss += criterion(val_logits, val_labels_gpu)\n            correct_pred_count += (torch.argmax(val_logits, dim=-1) == val_labels_gpu).sum()\n        val_acc = correct_pred_count / len(val_data) \n    model.train()\n    scheduler.step(val_loss)\n    print(f'epoch {epoch} train loss = {epoch_loss}, val loss = {val_loss}, val acc = {val_acc}')\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T04:57:15.920444Z","iopub.execute_input":"2025-10-17T04:57:15.920997Z","iopub.status.idle":"2025-10-17T05:48:46.113215Z","shell.execute_reply.started":"2025-10-17T04:57:15.920975Z","shell.execute_reply":"2025-10-17T05:48:46.112114Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 117/117 [13:36<00:00,  6.98s/it]","output_type":"stream"},{"name":"stdout","text":"epoch 0, train acc = 0.5296880602836609\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 30/30 [03:52<00:00,  7.75s/it]\n","output_type":"stream"},{"name":"stdout","text":"epoch 0 train loss = 169.05484008789062, val loss = 32.06291580200195, val acc = 0.6898309588432312\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 117/117 [13:20<00:00,  6.84s/it]\n","output_type":"stream"},{"name":"stdout","text":"epoch 1, train acc = 0.6659510731697083\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 30/30 [03:44<00:00,  7.48s/it]\n","output_type":"stream"},{"name":"stdout","text":"epoch 1 train loss = 122.30055236816406, val loss = 28.532520294189453, val acc = 0.711832582950592\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 117/117 [13:11<00:00,  6.76s/it]\n","output_type":"stream"},{"name":"stdout","text":"epoch 2, train acc = 0.6869507431983948\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 30/30 [03:44<00:00,  7.49s/it]","output_type":"stream"},{"name":"stdout","text":"epoch 2 train loss = 114.20797729492188, val loss = 27.755809783935547, val acc = 0.7096861004829407\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"ckpt = {\"state_dict\": model.state_dict()}\ntorch.save(ckpt, \"/kaggle/working/model_resnet18_fold0.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T05:49:02.918008Z","iopub.execute_input":"2025-10-17T05:49:02.918693Z","iopub.status.idle":"2025-10-17T05:49:03.001121Z","shell.execute_reply.started":"2025-10-17T05:49:02.918660Z","shell.execute_reply":"2025-10-17T05:49:03.000246Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"import pandas\n\nmodel.eval()\nall_files, all_idx = [], []\nfor test_image, file_names in test_loader:\n    test_image = test_image.to(device)\n    preds = torch.argmax(model(test_image), dim=-1).cpu().tolist()\n    all_idx.extend(preds)\n    all_files.extend(file_names)\n\ndf = pd.DataFrame({'image': all_files, 'lables': [train_dataset.idx2cls[i] for i in all_idx]})\ndf.to_csv('submission.csv', index=False)\ndf.head(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T04:56:50.524639Z","iopub.status.idle":"2025-10-17T04:56:50.524987Z","shell.execute_reply.started":"2025-10-17T04:56:50.524805Z","shell.execute_reply":"2025-10-17T04:56:50.524819Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(device, next(model.parameters()).device)\n!nvidia-smi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T04:56:50.531425Z","iopub.status.idle":"2025-10-17T04:56:50.534236Z","shell.execute_reply.started":"2025-10-17T04:56:50.534033Z","shell.execute_reply":"2025-10-17T04:56:50.534052Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}